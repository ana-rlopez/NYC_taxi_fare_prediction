{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "of4LCPeltVMG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from geopy.distance import geodesic\n",
    "import sklearn.feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn import linear_model\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbg0VE6P19xG"
   },
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "#add new features to df:\n",
    "def add_newFeats(df):\n",
    "    \n",
    "    #compute distance function\n",
    "    def haversine_distance(df_pickup_lat, df_pickup_long,df_dropoff_lat,df_dropoff_long):\n",
    "\n",
    "    #6367 earth radius\n",
    "        distance_col = 6367 * 2 * np.arcsin(np.sqrt(np.sin((np.radians(df_pickup_lat) /\n",
    "                                                - np.radians(df_dropoff_lat))/2)**2 /\n",
    "                                                + np.cos(np.radians(df_dropoff_lat))*np.cos(np.radians(df_pickup_lat))*np.sin((np.radians(df_pickup_long) - np.radians(df_dropoff_long))/2)**2))\n",
    "        return distance_col\n",
    "    \n",
    "     #add features related with datetime\n",
    "    df['key'] = pd.to_datetime(df['key'])\n",
    "    df['weekday'] = df['key'].dt.dayofweek\n",
    "    df['year']=df['key'].dt.year\n",
    "    df['month']=df['key'].dt.month\n",
    "    df['day']=df['key'].dt.day\n",
    "    df['hour']=df['key'].dt.hour\n",
    "\n",
    "    #Absolute differences between longitudes and between latitudes\n",
    "    df ['abs_diff_longitude']=np.abs(df.pickup_longitude-df.dropoff_longitude)\n",
    "    df ['abs_diff_latitude']=np.abs(df.pickup_latitude-df.dropoff_latitude)\n",
    "    \n",
    "    #there are some flat rates on trips from/to some of the airports in NY (JFK, LaGuardia, Newark) so we add features of\n",
    "    #distances from/to these airports\n",
    "    # coordinates from https://get-direction.com\n",
    "    jfk_latitude = 40.644538879\n",
    "    jfk_longitude = -73.795356750\n",
    "    laguardia_latitude = 40.774009705\n",
    "    laguardia_longitude =-73.872497559\n",
    "    newark_latitude = 40.692878723\n",
    "    newark_longitude = -74.185447693 \n",
    "        \n",
    "    #distances: between pickup and dropoffs, and distances to the main 3 airports in NYC\n",
    "    #note: Newark is actually New Jersey, that's also why the bounding box was also larger\n",
    "    df['distance'] = haversine_distance(df['pickup_latitude'],df['pickup_longitude'],df['dropoff_latitude'],df['dropoff_longitude'])\n",
    "    df['pickup_distance_jfk'] = haversine_distance(df['pickup_latitude'],df['pickup_longitude'],jfk_latitude, jfk_longitude)\n",
    "    df['pickup_distance_laguardia'] = haversine_distance(df['pickup_latitude'],df['pickup_longitude'],laguardia_latitude, laguardia_longitude)\n",
    "    df['pickup_distance_newark'] = haversine_distance(df['pickup_latitude'],df['pickup_longitude'],newark_latitude, newark_longitude)\n",
    "    df['dropoff_distance_jfk'] = haversine_distance(df['dropoff_latitude'],df['dropoff_longitude'],jfk_latitude, jfk_longitude)\n",
    "    df['dropoff_distance_newark'] = haversine_distance(df['dropoff_latitude'],df['dropoff_longitude'],newark_latitude, newark_longitude)\n",
    "\n",
    "    df['dropoff_distance_laguardia'] = haversine_distance(df['dropoff_latitude'],df['dropoff_longitude'],laguardia_latitude, laguardia_longitude)\n",
    "    \n",
    "    #log transform for distance help?\n",
    "    df['distance_log'] = df['distance'].transform(lambda x: np.log(x+sys.float_info.epsilon))\n",
    "    df['abs_diff_latitude_log'] = df['abs_diff_latitude'].transform(lambda x: np.log(x+sys.float_info.epsilon))\n",
    "    df['abs_diff_longitude_log'] = df['abs_diff_longitude'].transform(lambda x: np.log(x+sys.float_info.epsilon))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "31lNgv3Y2Sjk",
    "outputId": "e3af7b71-5307-42f6-fb8e-1fa6f574cb6b"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#train_path = '/content/drive/My Drive/Colab Notebooks/train.csv'\n",
    "train_path = 'train_orig.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "fNS7UyE9FWXh",
    "outputId": "e8809129-ab10-4b95-b377-94d56e3e0bb9"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path, nrows=1_000_000) #we don't select all rows, since it is a big dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "1btPygyu3z7y",
    "outputId": "fa670d30-5020-4b0a-ebe8-1b81c4e06aa6"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "8jW_Vb2zN29Q",
    "outputId": "4da9e4cb-d9ef-42c7-e145-14e7925b4c99"
   },
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing (denoising data) and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop outliers (given amount of data is large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RFcZ_C94W47i",
    "outputId": "55e1ee8c-f677-44b8-caad-afce37a07865"
   },
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "train.drop_duplicates(keep = 'first', inplace = True)\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mmChemjEL1Yf",
    "outputId": "65f69b23-40b1-48ff-9c48-27f0eeb89b56"
   },
   "outputs": [],
   "source": [
    "#we drop already some clear errors in data set (NaN rows, and duplicates)\n",
    "\n",
    "#check if there are some NaN values\n",
    "train.columns[train.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we drop these values given that the data set is quite big\n",
    "#original rows: 1_000_000\n",
    "train.dropna(inplace=True)\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we limit the coordinates to proper ranges to compute distances\n",
    "\n",
    "#Latitudes range from -90 to 90. Longitudes range from -180 to 180.\n",
    "train = train[ (train.pickup_longitude >= -180) & (train.pickup_longitude <= 180) & \\\n",
    "              (train.dropoff_longitude >= -180) & (train.dropoff_longitude <= 180) & \\\n",
    "              (train.pickup_latitude >= -90) & (train.pickup_latitude <= 90) & \\\n",
    "              (train.dropoff_latitude >= -90) & (train.dropoff_latitude <= 90) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HG_0v9GCTMWU"
   },
   "outputs": [],
   "source": [
    "#based on these descriptors, we can at first sight already remove some other outliers:\n",
    "#2) passengers in a taxi, up to 6 (icnluding suvs) https://ride.guru/lounge/p/how-many-people-can-ride-in-a-cab \n",
    "#leave drives of 0 passengers in case documents are transported?\n",
    "#3) fare has to be positive value, over 2.50$? (that seems to be the initial charge) https://www1.nyc.gov/site/tlc/passengers/taxi-fare.page\n",
    "#also fare now seems too high (500) and the variance is pretty hight too. so we cut the max fare now\n",
    "\n",
    "#4) new york city actually has the following bounding box of coordinates (https://boundingbox.klokantech.com/)\n",
    "#eastlimit_longitude=-73.700181\n",
    "#southlimit_latitude =40.47739894\n",
    "#westlimit_longitude=-74.25909\n",
    "#northlimit_latitude=40.916178\n",
    "\n",
    "\n",
    "#trying to use a bounding box slightly larger than the actual NY, so there is more flexibility for trips around airport\n",
    "eastlimit_longitude=-73.664465\n",
    "southlimit_latitude=40.477399\n",
    "westlimit_longitude=-74.307165\n",
    "northlimit_latitude=40.935154\n",
    "                                                                                                               \n",
    "train = train[ (train.pickup_longitude >= westlimit_longitude) & (train.pickup_longitude <= eastlimit_longitude) & \\\n",
    "              (train.dropoff_longitude >= westlimit_longitude) & (train.dropoff_longitude <= eastlimit_longitude) & \\\n",
    "              (train.pickup_latitude >= southlimit_latitude ) & (train.pickup_latitude <= northlimit_latitude) & \\\n",
    "              (train.dropoff_latitude >= southlimit_latitude) & (train.dropoff_latitude <= northlimit_latitude) ]                                                                              \n",
    "\n",
    "train = train[(train.passenger_count<= 6) & \\\n",
    "              (train.fare_amount > 2.50)  ]\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fare_amount.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[ (train.fare_amount < 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_newFeats(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "yqBMJKJkx_uF",
    "outputId": "385812cb-9f4a-4dd1-b6bf-89645d447735"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the cases of distances = 0 that we were going to keep seem to decrease the performance,\n",
    "#so all cases are removed:\n",
    "#removed any row with distance equal to 0:\n",
    "train = train[ (train.distance > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization (exploratory analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "V4TyLFuIiMJm",
    "outputId": "1a6422f4-0cab-4e7d-f928-a27914cdf8e6"
   },
   "outputs": [],
   "source": [
    "#check distributions of all the features\n",
    "fig = plt.figure(figsize = (15,20))\n",
    "ax = fig.gca()\n",
    "train.hist(ax = ax, bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-RvXNKyv8Db"
   },
   "outputs": [],
   "source": [
    "corr_pearson = train.corr(method='pearson')\n",
    "mask = np.zeros_like(corr_pearson, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "yZVa4uFLwDbb",
    "outputId": "1cbd6831-a812-47fa-965c-32a1f945c0f8"
   },
   "outputs": [],
   "source": [
    "fig4, ax4 = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(corr_pearson, mask=mask, cmap='RdBu_r', vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5},vmin=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gRzX-1pIznyU"
   },
   "outputs": [],
   "source": [
    "#visualizer = FeatureCorrelation( method='mutual_info-classification', feature_names=train_out.columns, sort=True)\n",
    "X = train.drop(['fare_amount','key','pickup_datetime'],axis=1, inplace=False).to_numpy()\n",
    "Y = train.fare_amount.to_numpy()\n",
    "#lab_enc = sklearn.preprocessing.LabelEncoder()\n",
    "#Y_encoded = lab_enc.fit_transform(Y)\n",
    "\n",
    "#mutual information has too expensive computationally to run for all data, so we just take \n",
    "X = X[1:100000,:]\n",
    "Y = Y[1:100000]\n",
    "\n",
    "feature_MIscores = sklearn.feature_selection.mutual_info_regression(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTCn7xtRxwc2"
   },
   "outputs": [],
   "source": [
    "feature_MIscores.shape\n",
    "\n",
    "#plot also the fare vs the date (year), and maybe check as hypothesis if there is a positive correlation between year and fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_labels = train.drop(['fare_amount','key','pickup_datetime'],axis=1, inplace=False).columns\n",
    "#print(feats_labels)\n",
    "index = np.arange(len(feats_labels))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(index, feature_MIscores)\n",
    "plt.xlabel('mutual information score', fontsize=20)\n",
    "plt.yticks(index, feats_labels, fontsize=10, rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(train, y_vars=['fare_amount'], x_vars=['distance', 'distance_log', 'hour','day','month','year','weekday','passenger_count','dropoff_latitude','dropoff_longitude','pickup_latitude','pickup_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"distance\", y=\"fare_amount\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is also a kind of straight line, that can be explained by the flat rates used for taxi rides from airport\n",
    " #\"Taxis at JFK Airport charge a flat fare of $52 for trips between the airport and Manhattan.\" \n",
    "#https://www.jfkairport.com/to-from-airport/taxi-car-and-van-service\n",
    "sns.scatterplot(x=\"distance_log\", y=\"fare_amount\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using hex bins because regular scatter plot does not work (too many points)\n",
    "sns.jointplot(x=\"distance\", y=\"fare_amount\", data=train, kind='reg',joint_kws={'line_kws':{'color':'cyan'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using hex bins because regular scatter plot does not work (too many points)\n",
    "#easier to see with dostance_log since the scale is shrunk\n",
    "sns.jointplot(x=\"distance\", y=\"fare_amount\", data=train, kind='hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_KbEzhXAzd4S"
   },
   "outputs": [],
   "source": [
    "#TODO: maybe also plot histograms grouping by day, or by hour, to see what times are more common, and see if the fair is similar for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUX0PGFRy-OP"
   },
   "outputs": [],
   "source": [
    "#TODO:maybe a heat map of the fares would be interesting, doing a geomap, maybe use plotly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: maybe employ clustering to get some extra information of the data, like outliers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split of training data (train + validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, val = train_test_split(train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling \n",
    "### (Comparison of several regression models, plus a dummy model as baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_set1=['year','distance','pickup_distance_jfk','pickup_distance_laguardia',\\\n",
    "                  'dropoff_distance_jfk','dropoff_distance_laguardia','abs_diff_latitude','abs_diff_longitude','dropoff_distance_newark','pickup_distance_newark']\n",
    "\n",
    "X_train = train2[features_set1]\n",
    "y_train = train2[['fare_amount']]\n",
    "\n",
    "X_val = val[features_set1]\n",
    "y_val = val[['fare_amount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "t0_dummy=time()\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "print(\"Dummy model regression, training time:\" + str(round(time()-t0_dummy, 3)) + \"s\")\n",
    "print(dummy_regr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valPred_dummy = dummy_regr.predict(X_val)\n",
    "y_trainPred_dummy = dummy_regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 is the proportion of the variance in the dependent variable that is predictable from the independent\n",
    "#variable(s).\n",
    "\n",
    "r2_val_dummy = r2_score(y_val, y_valPred_dummy)\n",
    "r2_train_dummy = r2_score(y_train, y_trainPred_dummy)\n",
    "\n",
    "print('Dummy model- training, R2:' + str(r2_train_dummy))\n",
    "print('Dummy model- validation, R2:' + str(r2_val_dummy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_val_dummy = mean_squared_error(y_val, y_valPred_dummy)\n",
    "mse_train_dummy = mean_squared_error(y_train, y_trainPred_dummy)\n",
    "\n",
    "print('Dummy model - training, MSE:' + str(mse_train_dummy))\n",
    "print('Dummy model - validation, MSE:' + str(mse_val_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "#use same scaler for both, based on X_train data\n",
    "X_trainNorm = scaler.transform(X_train)\n",
    "X_valNorm = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression model\n",
    "linRegr = linear_model.LinearRegression()\n",
    "print(linRegr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with training data\n",
    "\n",
    "t0_linR=time()\n",
    "linRegr.fit(X_trainNorm, y_train)\n",
    "print(\"Linear regression, training time:\" + str(round(time()-t0_linR, 3)) + \"s\")\n",
    "print(linRegr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valPred_linReg = linRegr.predict(X_valNorm) #to check validation error measures\n",
    "y_trainPred_linReg = linRegr.predict(X_trainNorm) #to check training error measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_val_linReg = r2_score(y_val, y_valPred_linReg)\n",
    "r2_train_linReg = r2_score(y_train, y_trainPred_linReg)\n",
    "\n",
    "print('Linear regression - training, R2:' + str(r2_train_linReg))\n",
    "print('Linear regression - validation, R2:' + str(r2_val_linReg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_val_linReg = mean_squared_error(y_val, y_valPred_linReg)\n",
    "mse_train_linReg = mean_squared_error(y_train, y_trainPred_linReg)\n",
    "\n",
    "print('Linear regression - training, MSE:' + str(mse_train_linReg))\n",
    "print('Linear regression - validation, MSE:' + str(mse_val_linReg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with Lasso regularization (i.e. feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lasso = train2.drop(['fare_amount','key','pickup_datetime','distance_log','abs_diff_latitude_log','abs_diff_longitude_log'],axis=1, inplace=False)\n",
    "y_train_lasso = train2[['fare_amount']]\n",
    "\n",
    "X_val_lasso = val.drop(['fare_amount','key','pickup_datetime','distance_log','abs_diff_latitude_log','abs_diff_longitude_log'],axis=1, inplace=False)\n",
    "y_val_lasso = val[['fare_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lasso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lasso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_lasso = StandardScaler()\n",
    "scaler_lasso.fit(X_train_lasso)\n",
    "\n",
    "#use same scaler for both, based on X_train_lasso data\n",
    "X_trainLassoNorm = scaler_lasso.transform(X_train_lasso)\n",
    "X_valLassoNorm = scaler_lasso.transform(X_val_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoReg = linear_model.LassoCV(cv=5)\n",
    "t0_linRLasso=time()\n",
    "lassoReg.fit(X_trainLassoNorm, y_train_lasso.values.ravel())\n",
    "print(\"Linear regression with Lasso reg., training time:\" + str(round(time()-t0_linRLasso, 3)) + \"s\")\n",
    "print(lassoReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valPred_lassoReg = lassoReg.predict(X_valLassoNorm)\n",
    "y_trainPred_lassoReg = lassoReg.predict(X_trainLassoNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_val_lassoReg = r2_score(y_val_lasso, y_valPred_lassoReg)\n",
    "r2_train_lassoReg = r2_score(y_train_lasso, y_trainPred_lassoReg)\n",
    "\n",
    "print('Linear regression with Lasso reg. - training, R2:' + str(r2_train_lassoReg))\n",
    "print('Linear regression with Lasso reg. - validation, R2:' + str(r2_val_lassoReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_val_lassoReg = mean_squared_error(y_val_lasso, y_valPred_lassoReg)\n",
    "mse_train_lassoReg = mean_squared_error(y_train_lasso, y_trainPred_lassoReg)\n",
    "\n",
    "print('Linear regression with Lasso reg. - training, MSE:' + str(mse_train_lassoReg))\n",
    "print('Linear regression with Lasso reg. - validation, MSE:' + str(mse_val_lassoReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: include a plotbar showing the weights obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest regression\n",
    "\n",
    "Decision trees can deal with non-linearity relationships between independent variables and the dependent variable (fare_amount), unlike linear regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randFor = RandomForestRegressor(n_estimators=10) #current default, future is 100, but it is too much computation\n",
    "\n",
    "#decisions trees don't need normalized data since they don't assume any distribution\n",
    "\n",
    "t0_randFor=time()\n",
    "randFor.fit(X_train_lasso, y_train_lasso.values.ravel())\n",
    "print(\"Random forest regression, training time:\" + str(round(time()-t0_randFor, 3)) + \"s\")\n",
    "print(randFor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = randFor.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features =  X_train_lasso.columns\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Avenues generally run north and south in NY.\n",
    "# all streets run east and west\n",
    "#https://becomeanewyorker.com/streets-and-avenues-there-is-a-differenc/\n",
    "#it may be that taxis go mainly through avenues, and that is why longitude affects so much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valPred_randFor = randFor.predict(X_val_lasso)\n",
    "y_trainPred_randFor = randFor.predict(X_train_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_val_randFor = r2_score(y_val_lasso, y_valPred_randFor)\n",
    "r2_train_randFor = r2_score(y_train_lasso, y_trainPred_randFor)\n",
    "\n",
    "print('Random forest regression - training, R2:' + str(r2_train_randFor))\n",
    "print('Random forest regression - validation, R2:' + str(r2_val_randFor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_val_randFor = mean_squared_error(y_val_lasso, y_valPred_randFor)\n",
    "mse_train_randFor = mean_squared_error(y_train_lasso, y_trainPred_randFor)\n",
    "\n",
    "print('Random forest regression - training, MSE:' + str(mse_train_randFor))\n",
    "print('Random forest regression - validation, MSE:' + str(mse_val_randFor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost regression\n",
    "\n",
    "With this approach with reduce not only variance (as in random forests) but also the bias.\n",
    "It has also regularization to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://datascience.stackexchange.com/questions/23789/why-do-we-need-xgboost-and-random-forest\n",
    "#xgbr = xgb.XGBRegressor(objective ='reg:squarederror')  #objective changed based on warning: \"reg:linear is now deprecated in favor of reg:squarederror.\"\n",
    "#print(xgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again here, using decision trees, so no need \n",
    "\n",
    "#t0_xgbr=time()\n",
    "#xgbr.fit(X_train_lasso, y_train_lasso.values.ravel())\n",
    "#print(\"XGBoost regression, training time:\" + str(round(time()-t0_xgbr, 3)) + \"s\")\n",
    "#print(xgbr)\n",
    "\n",
    "#filename = 'XGBoost_model.sav'\n",
    "#pickle.dump(xgbr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_valPred_xgbr = xgbr.predict(X_val_lasso)\n",
    "#y_trainPred_xgbr = xgbr.predict(X_train_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2_val_xgbr = r2_score(y_val_lasso, y_valPred_xgbr)\n",
    "#r2_train_xgbr = r2_score(y_train_lasso, y_trainPred_xgbr)\n",
    "\n",
    "#print('XGBoost regression - training, R2:' + str(r2_train_xgbr))\n",
    "#print('XGBoost regression - validation, R2:' + str(r2_val_xgbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse_val_xgbr = mean_squared_error(y_val_lasso, y_valPred_xgbr)\n",
    "#mse_train_xgbr = mean_squared_error(y_train_lasso, y_trainPred_xgbr)\n",
    "\n",
    "#print('XGBoost regression - training, MSE:' + str(mse_train_xgbr))\n",
    "#print('XGBoost forest regression - validation, MSE:' + str(mse_val_xgbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### XGBoost with parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/omarito/gridsearchcv-xgbregressor-0-556-lb\n",
    "#https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "#https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that are going to be tuned are those given by an :\n",
    "params ={}\n",
    "params = {\n",
    "    'max_depth': [3,5,7,9],\n",
    "    'min_child_weight': [1,3,5],\n",
    "    'learning_rate': [0.05,0.1,0.3],\n",
    "    'subsample': [1],\n",
    "    'colsample_bytree': [1],\n",
    "    # Other parameters\n",
    "    'objective': ['reg:squarederror'],\n",
    "}\n",
    "#num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing XGBoost and GridSearchCV\n",
    "\n",
    "#k=10 #10-folding\n",
    "#xgb_regr_tuning = xgb.XGBRegressor() \n",
    "#xgbr_grid = GridSearchCV(xgb_regr_tuning, params, cv=k, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##we use just a subset of the values, otherwise it takes too much time \n",
    "##(also, batches will be smaller, which may be better for results in the end)\n",
    "#X_train_grid = X_train_lasso.head(300_000)\n",
    "#y_train_grid = y_train_lasso.head(300_000)\n",
    "\n",
    "#t0_xgbrGrid=time()\n",
    "#grid_result = xgbr_grid.fit(X_train_grid, y_train_grid.values.ravel())\n",
    "#print(\"XGBoost grid search tuning, time:\" + str(round(time()-t0_xgbrGrid, 3)) + \"s\")\n",
    "#print(xgbr_grid)\n",
    "\n",
    "#filename = 'XGBoostGrid_model.sav'\n",
    "#pickle.dump(grid_result, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_params = grid_result.best_params_\n",
    "#params['max_depth']=[best_params['max_depth']]\n",
    "#params['min_child_weight']=[best_params['min_child_weight']]\n",
    "#params['learning_rate']=[best_params['learning_rate']]\n",
    "\n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_xgbr = xgb.XGBRegressor(max_depth=9,min_child_weight=1,learning_rate= 0.1,objective ='reg:squarederror')\n",
    "#t0_xgbrTune=time()\n",
    "#tuned_xgbr.fit(X_train_lasso, y_train_lasso.values.ravel())\n",
    "#print(\"XGBoost regression with tuning, training time:\" + str(round(time()-t0_xgbrTune, 3)) + \"s\")\n",
    "#print(xgbr_grid)\n",
    "\n",
    "filename = 'XGBoostTuned_model.sav'\n",
    "#pickle.dump(tuned_xgbr, open(filename, 'wb'))\n",
    "tuned_xgbr = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_valPred_xgbrGrid = xgbr_grid.predict(X_val_lasso)\n",
    "#y_trainPred_xgbrGrid = xgbr_grid.predict(X_train_lasso)\n",
    "\n",
    "y_valPred_tuned_xgbr = tuned_xgbr.predict(X_val_lasso)\n",
    "y_trainPred_tuned_xgbr = tuned_xgbr.predict(X_train_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2_val_xgbrGrid = r2_score(y_val_lasso, y_valPred_xgbrGrid)\n",
    "#r2_train_xgbrGrid = r2_score(y_train_lasso, y_trainPred_xgbrGrid)\n",
    "r2_val_tuned_xgbr = r2_score(y_val_lasso, y_valPred_tuned_xgbr)\n",
    "r2_train_tuned_xgbr = r2_score(y_train_lasso, y_trainPred_tuned_xgbr)\n",
    "\n",
    "\n",
    "#print('XGBoost regression, with tuning - training, R2:' + str(r2_train_xgbrGrid))\n",
    "#print('XGBoost regression, with tuning - validation, R2:' + str(r2_val_xgbrGrid))\n",
    "\n",
    "print('XGBoost regression, with tuning - training, R2:' + str(r2_train_tuned_xgbr))\n",
    "print('XGBoost regression, with tuning - validation, R2:' + str(r2_val_tuned_xgbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse_val_xgbrGrid = mean_squared_error(y_val_lasso, y_valPred_xgbrGrid)\n",
    "#mse_train_xgbrGrid = mean_squared_error(y_train_lasso, y_trainPred_xgbrGrid)\n",
    "\n",
    "mse_val_tuned_xgbr = mean_squared_error(y_val_lasso, y_valPred_tuned_xgbr)\n",
    "mse_train_tuned_xgbr = mean_squared_error(y_train_lasso, y_trainPred_tuned_xgbr)\n",
    "\n",
    "print('XGBoost regression - training, MSE:' + str(mse_train_tuned_xgbr))\n",
    "print('XGBoost forest regression - validation, MSE:' + str(mse_val_tuned_xgbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#been on end of notebook running\n",
    "import os\n",
    "duration = 1  # seconds\n",
    "freq = 400  # Hz\n",
    "os.system('play -nq -t alsa synth {} sine {}'.format(duration, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "      <td>2015-01-27 13:08:24 UTC</td>\n",
       "      <td>-73.973320</td>\n",
       "      <td>40.763805</td>\n",
       "      <td>-73.981430</td>\n",
       "      <td>40.743835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 13:08:24.0000003</td>\n",
       "      <td>2015-01-27 13:08:24 UTC</td>\n",
       "      <td>-73.986862</td>\n",
       "      <td>40.719383</td>\n",
       "      <td>-73.998886</td>\n",
       "      <td>40.739201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-08 11:53:44.0000002</td>\n",
       "      <td>2011-10-08 11:53:44 UTC</td>\n",
       "      <td>-73.982524</td>\n",
       "      <td>40.751260</td>\n",
       "      <td>-73.979654</td>\n",
       "      <td>40.746139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 21:12:12.0000002</td>\n",
       "      <td>2012-12-01 21:12:12 UTC</td>\n",
       "      <td>-73.981160</td>\n",
       "      <td>40.767807</td>\n",
       "      <td>-73.990448</td>\n",
       "      <td>40.751635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 21:12:12.0000003</td>\n",
       "      <td>2012-12-01 21:12:12 UTC</td>\n",
       "      <td>-73.966046</td>\n",
       "      <td>40.789775</td>\n",
       "      <td>-73.988565</td>\n",
       "      <td>40.744427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           key          pickup_datetime  pickup_longitude  \\\n",
       "0  2015-01-27 13:08:24.0000002  2015-01-27 13:08:24 UTC        -73.973320   \n",
       "1  2015-01-27 13:08:24.0000003  2015-01-27 13:08:24 UTC        -73.986862   \n",
       "2  2011-10-08 11:53:44.0000002  2011-10-08 11:53:44 UTC        -73.982524   \n",
       "3  2012-12-01 21:12:12.0000002  2012-12-01 21:12:12 UTC        -73.981160   \n",
       "4  2012-12-01 21:12:12.0000003  2012-12-01 21:12:12 UTC        -73.966046   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.763805         -73.981430         40.743835                1  \n",
       "1        40.719383         -73.998886         40.739201                1  \n",
       "2        40.751260         -73.979654         40.746139                1  \n",
       "3        40.767807         -73.990448         40.751635                1  \n",
       "4        40.789775         -73.988565         40.744427                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = 'test_orig.csv'\n",
    "test = pd.read_csv(test_path)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-73.974722</td>\n",
       "      <td>40.751041</td>\n",
       "      <td>-73.973657</td>\n",
       "      <td>40.751743</td>\n",
       "      <td>1.671273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.042774</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>0.039072</td>\n",
       "      <td>0.035435</td>\n",
       "      <td>1.278747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-74.252193</td>\n",
       "      <td>40.573143</td>\n",
       "      <td>-74.263242</td>\n",
       "      <td>40.568973</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-73.992501</td>\n",
       "      <td>40.736125</td>\n",
       "      <td>-73.991247</td>\n",
       "      <td>40.735254</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-73.982326</td>\n",
       "      <td>40.753051</td>\n",
       "      <td>-73.980015</td>\n",
       "      <td>40.754065</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-73.968013</td>\n",
       "      <td>40.767113</td>\n",
       "      <td>-73.964059</td>\n",
       "      <td>40.768757</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-72.986532</td>\n",
       "      <td>41.709555</td>\n",
       "      <td>-72.990963</td>\n",
       "      <td>41.696683</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "count       9914.000000      9914.000000        9914.000000       9914.000000   \n",
       "mean         -73.974722        40.751041         -73.973657         40.751743   \n",
       "std            0.042774         0.033541           0.039072          0.035435   \n",
       "min          -74.252193        40.573143         -74.263242         40.568973   \n",
       "25%          -73.992501        40.736125         -73.991247         40.735254   \n",
       "50%          -73.982326        40.753051         -73.980015         40.754065   \n",
       "75%          -73.968013        40.767113         -73.964059         40.768757   \n",
       "max          -72.986532        41.709555         -72.990963         41.696683   \n",
       "\n",
       "       passenger_count  \n",
       "count      9914.000000  \n",
       "mean          1.671273  \n",
       "std           1.278747  \n",
       "min           1.000000  \n",
       "25%           1.000000  \n",
       "50%           1.000000  \n",
       "75%           2.000000  \n",
       "max           6.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = add_newFeats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is clean of NaNs\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill using median rather than mean since it is more robust to outliers\n",
    "#test['weekday'].fillna((test['weekday'].median()), inplace=True)\n",
    "#test['year'].fillna((test['year'].median()), inplace=True)\n",
    "#test['month'].fillna((test['month'].median()), inplace=True)\n",
    "#test['hour'].fillna((test['hour'].median()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check also about the coordinates\n",
    "\n",
    "test[ (test.pickup_longitude < -180) | (test.pickup_longitude > 180) | \\\n",
    "              (test.dropoff_longitude < -180) | (test.dropoff_longitude > 180) | \\\n",
    "              (test.pickup_latitude < -90) | (test.pickup_latitude > 90) | \\\n",
    "              (test.dropoff_latitude < -90) | (test.dropoff_latitude > 90) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test.distance == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = test.drop(['key','pickup_datetime','distance_log','abs_diff_latitude_log','abs_diff_longitude_log'],axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>abs_diff_longitude</th>\n",
       "      <th>abs_diff_latitude</th>\n",
       "      <th>distance</th>\n",
       "      <th>pickup_distance_jfk</th>\n",
       "      <th>pickup_distance_laguardia</th>\n",
       "      <th>pickup_distance_newark</th>\n",
       "      <th>dropoff_distance_jfk</th>\n",
       "      <th>dropoff_distance_newark</th>\n",
       "      <th>dropoff_distance_laguardia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "      <td>9914.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-73.974722</td>\n",
       "      <td>40.751041</td>\n",
       "      <td>-73.973657</td>\n",
       "      <td>40.751743</td>\n",
       "      <td>1.671273</td>\n",
       "      <td>2.852834</td>\n",
       "      <td>2011.815816</td>\n",
       "      <td>6.857979</td>\n",
       "      <td>16.194170</td>\n",
       "      <td>13.467420</td>\n",
       "      <td>0.023348</td>\n",
       "      <td>0.022133</td>\n",
       "      <td>1.243933</td>\n",
       "      <td>9.648597</td>\n",
       "      <td>5.685396</td>\n",
       "      <td>11.237838</td>\n",
       "      <td>9.570293</td>\n",
       "      <td>11.294917</td>\n",
       "      <td>5.551162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.042774</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>0.039072</td>\n",
       "      <td>0.035435</td>\n",
       "      <td>1.278747</td>\n",
       "      <td>1.994451</td>\n",
       "      <td>1.803347</td>\n",
       "      <td>3.353272</td>\n",
       "      <td>8.838482</td>\n",
       "      <td>6.868584</td>\n",
       "      <td>0.036719</td>\n",
       "      <td>0.025589</td>\n",
       "      <td>1.958653</td>\n",
       "      <td>1.933168</td>\n",
       "      <td>1.589563</td>\n",
       "      <td>2.283139</td>\n",
       "      <td>1.812506</td>\n",
       "      <td>2.083768</td>\n",
       "      <td>1.597437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-74.252193</td>\n",
       "      <td>40.573143</td>\n",
       "      <td>-74.263242</td>\n",
       "      <td>40.568973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009949</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>1.905468</td>\n",
       "      <td>0.041663</td>\n",
       "      <td>0.088896</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-73.992501</td>\n",
       "      <td>40.736125</td>\n",
       "      <td>-73.991247</td>\n",
       "      <td>40.735254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.006354</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.338505</td>\n",
       "      <td>9.220034</td>\n",
       "      <td>5.094757</td>\n",
       "      <td>10.287253</td>\n",
       "      <td>9.010791</td>\n",
       "      <td>10.354199</td>\n",
       "      <td>4.904470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-73.982326</td>\n",
       "      <td>40.753051</td>\n",
       "      <td>-73.980015</td>\n",
       "      <td>40.754065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.014715</td>\n",
       "      <td>0.699284</td>\n",
       "      <td>9.979375</td>\n",
       "      <td>5.851000</td>\n",
       "      <td>10.833266</td>\n",
       "      <td>9.855911</td>\n",
       "      <td>10.952961</td>\n",
       "      <td>5.731228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-73.968013</td>\n",
       "      <td>40.767113</td>\n",
       "      <td>-73.964059</td>\n",
       "      <td>40.768757</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.024557</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>1.308633</td>\n",
       "      <td>10.521719</td>\n",
       "      <td>6.393444</td>\n",
       "      <td>11.599358</td>\n",
       "      <td>10.453130</td>\n",
       "      <td>11.808672</td>\n",
       "      <td>6.326527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-72.986532</td>\n",
       "      <td>41.709555</td>\n",
       "      <td>-72.990963</td>\n",
       "      <td>41.696683</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.849168</td>\n",
       "      <td>0.633213</td>\n",
       "      <td>45.645175</td>\n",
       "      <td>43.763288</td>\n",
       "      <td>47.844913</td>\n",
       "      <td>64.822849</td>\n",
       "      <td>43.515665</td>\n",
       "      <td>64.571588</td>\n",
       "      <td>47.597004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "count       9914.000000      9914.000000        9914.000000       9914.000000   \n",
       "mean         -73.974722        40.751041         -73.973657         40.751743   \n",
       "std            0.042774         0.033541           0.039072          0.035435   \n",
       "min          -74.252193        40.573143         -74.263242         40.568973   \n",
       "25%          -73.992501        40.736125         -73.991247         40.735254   \n",
       "50%          -73.982326        40.753051         -73.980015         40.754065   \n",
       "75%          -73.968013        40.767113         -73.964059         40.768757   \n",
       "max          -72.986532        41.709555         -72.990963         41.696683   \n",
       "\n",
       "       passenger_count      weekday         year        month          day  \\\n",
       "count      9914.000000  9914.000000  9914.000000  9914.000000  9914.000000   \n",
       "mean          1.671273     2.852834  2011.815816     6.857979    16.194170   \n",
       "std           1.278747     1.994451     1.803347     3.353272     8.838482   \n",
       "min           1.000000     0.000000  2009.000000     1.000000     1.000000   \n",
       "25%           1.000000     1.000000  2010.000000     4.000000     9.000000   \n",
       "50%           1.000000     3.000000  2012.000000     7.000000    16.000000   \n",
       "75%           2.000000     5.000000  2014.000000    10.000000    25.000000   \n",
       "max           6.000000     6.000000  2015.000000    12.000000    31.000000   \n",
       "\n",
       "              hour  abs_diff_longitude  abs_diff_latitude     distance  \\\n",
       "count  9914.000000         9914.000000        9914.000000  9914.000000   \n",
       "mean     13.467420            0.023348           0.022133     1.243933   \n",
       "std       6.868584            0.036719           0.025589     1.958653   \n",
       "min       0.000000            0.000000           0.000000     0.000000   \n",
       "25%       8.000000            0.006354           0.007279     0.338505   \n",
       "50%      15.000000            0.013123           0.014715     0.699284   \n",
       "75%      19.000000            0.024557           0.028261     1.308633   \n",
       "max      23.000000            0.849168           0.633213    45.645175   \n",
       "\n",
       "       pickup_distance_jfk  pickup_distance_laguardia  pickup_distance_newark  \\\n",
       "count          9914.000000                9914.000000             9914.000000   \n",
       "mean              9.648597                   5.685396               11.237838   \n",
       "std               1.933168                   1.589563                2.283139   \n",
       "min               0.009949                   0.005357                1.905468   \n",
       "25%               9.220034                   5.094757               10.287253   \n",
       "50%               9.979375                   5.851000               10.833266   \n",
       "75%              10.521719                   6.393444               11.599358   \n",
       "max              43.763288                  47.844913               64.822849   \n",
       "\n",
       "       dropoff_distance_jfk  dropoff_distance_newark  \\\n",
       "count           9914.000000              9914.000000   \n",
       "mean               9.570293                11.294917   \n",
       "std                1.812506                 2.083768   \n",
       "min                0.041663                 0.088896   \n",
       "25%                9.010791                10.354199   \n",
       "50%                9.855911                10.952961   \n",
       "75%               10.453130                11.808672   \n",
       "max               43.515665                64.571588   \n",
       "\n",
       "       dropoff_distance_laguardia  \n",
       "count                 9914.000000  \n",
       "mean                     5.551162  \n",
       "std                      1.597437  \n",
       "min                      0.000563  \n",
       "25%                      4.904470  \n",
       "50%                      5.731228  \n",
       "75%                      6.326527  \n",
       "max                     47.597004  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testPred_tuned_xgbr = tuned_xgbr.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9914,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testPred_tuned_xgbr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['fare_amount'] = y_testPred_tuned_xgbr\n",
    "submission.to_csv('submission_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "      <td>10.473106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 13:08:24.0000003</td>\n",
       "      <td>10.243099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-08 11:53:44.0000002</td>\n",
       "      <td>4.685626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 21:12:12.0000002</td>\n",
       "      <td>8.538606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 21:12:12.0000003</td>\n",
       "      <td>15.312421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           key  fare_amount\n",
       "0  2015-01-27 13:08:24.0000002    10.473106\n",
       "1  2015-01-27 13:08:24.0000003    10.243099\n",
       "2  2011-10-08 11:53:44.0000002     4.685626\n",
       "3  2012-12-01 21:12:12.0000002     8.538606\n",
       "4  2012-12-01 21:12:12.0000003    15.312421"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NYTaxiFare_1_ExploratoryAnalysis_&_Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kernpy3",
   "language": "python",
   "name": "kernpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
